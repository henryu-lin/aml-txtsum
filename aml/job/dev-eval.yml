$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
experiment_name: hf-eval
description: batch size memory test (txtsum pegasus fp16 ddp sortish_sampler)
code:
    local_path: ../../exp
command: >
    python trainer-wip.py 
    --model_name_or_path "google/pegasus-xsum" 
    --dataset_name "xsum" 
    --dataset_path {inputs.corpus} 
    --max_source_length 512 
    --max_target_length 64 
    --seed 322 
    --fp16 True 
    --adafactor True 
    --label_smoothing_factor 0.1 
    --sortish_sampler True 
    --per_device_eval_batch_size 32 
    --predict_with_generate 
    --do_predict 
    --ddp_find_unused_parameters False 
    --output_dir "./outputs/hf-eval" 
    --logging_dir "./logs" 
    --cache_dir "./cache"
environment: azureml:hf-gpu:1
inputs:
    corpus:
        data: azureml:hf-xsum:1
        mode: download
compute:
    target: azureml:gpu-v100-8
    instance_count: 1
distribution:
  type: pytorch
  process_count: 8