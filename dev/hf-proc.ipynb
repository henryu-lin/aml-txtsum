{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\r\n",
        "#nltk.download('punkt')\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import datasets\r\n",
        "from datasets import load_dataset, load_from_disk\r\n",
        "#from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, HfArgumentParser\r\n",
        "#from transformers.integrations import MLflowCallback, AzureMLCallback"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1620779315956
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`wget http://bollin.inf.ed.ac.uk/public/direct/XSUM-EMNLP18-Summary-Data-Original.tar.gz`  \r\n",
        "XSUM: train(204,045) val(11,332) test(11,334)  \r\n",
        "doc: word(431.07) sent(19.77)  \r\n",
        "sum: word(23.26) sent(1.00)  \r\n",
        "voc: doc(399,147) sum(81,092)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit-dota-proc\r\n",
        "# num_rows: 19949\r\n",
        "data = load_from_disk(\"../data/reddit-dota-proc\")\r\n",
        "#data.train_test_split(test_size=0.1, shuffle=True)\r\n",
        "data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620779409000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit-dota-tiny\r\n",
        "max_text_length = 1024\r\n",
        "min_summary_length = 20\r\n",
        "max_ratio = 0.5\r\n",
        "min_ratio = 0.01\r\n",
        "dota = data.filter(lambda x: len(x[\"text\"]) <= max_text_length)\r\n",
        "dota = dota.filter(lambda x: len(x[\"summary\"]) >= min_summary_length)\r\n",
        "dota = dota.filter(lambda x: len(x[\"summary\"])/len(x[\"text\"]) <= max_ratio)\r\n",
        "dota = dota.filter(lambda x: len(x[\"summary\"])/len(x[\"text\"]) >= min_ratio)\r\n",
        "dota = dota.filter(lambda x: not x[\"text\"].endswith(\":\"))\r\n",
        "dota = dota.filter(lambda x: not x[\"summary\"].endswith(\":\"))\r\n",
        "dota = dota.filter(lambda x: not x[\"text\"].endswith(\",\"))\r\n",
        "dota = dota.filter(lambda x: not x[\"summary\"].endswith(\",\"))\r\n",
        "#dota.flatten_indices().save_to_disk(\"../data/reddit-dota-tiny\")\r\n",
        "dota"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620780179279
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reddit-dota-tiny\r\n",
        "# num_rows: 4135\r\n",
        "dota = dota.filter(lambda x: x[\"text\"].endswith(\".\"))\r\n",
        "dota = dota.filter(lambda x: x[\"summary\"].endswith(\".\"))\r\n",
        "dota = dota.filter(lambda x: x[\"text\"][0].isupper())\r\n",
        "dota = dota.filter(lambda x: x[\"summary\"][0].isupper())\r\n",
        "dota"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620780531996
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dota.flatten_indices().save_to_disk(\"../data/reddit-dota-tiny\")\r\n",
        "#dota[\"text\"][100:110]\r\n",
        "#dota[\"summary\"][100:110]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620780727089
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\r\n",
        "#from datasets import load_dataset, load_from_disk\r\n",
        "\r\n",
        "train, val, test = load_dataset(\"amazon_reviews_multi\", \"en\", split=[\"train[:1024]\", \"validation[:256]\", \"test[:64]\"], cache_dir=\"../cache\")\r\n",
        "data = load_dataset(\"amazon_reviews_multi\", \"en\", cache_dir=\"../cache\")\r\n",
        "train = data[\"train\"].select(range(64))\r\n",
        "test = data[\"test\"].select(range(64))\r\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\r\n",
        "# amazon reviews\r\n",
        "# remove all summaries with ...\r\n",
        "new = train.remove_columns([\"product_id\", \"stars\", \"review_id\", \"reviewer_id\", \"language\", \"product_category\"])\r\n",
        "new = new.rename_column(\"review_body\", \"text\").rename_column(\"review_title\", \"summary\")\r\n",
        "new = new.filter(lambda x: not x[\"summary\"].endswith(\"...\"))\r\n",
        "new = new.filter(lambda x: len(x[\"summary\"]) > 20)\r\n",
        "new[0]\r\n",
        "```"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}