{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "#!transformers-cli login\r\n",
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\r\n",
    "!sudo apt-get install git-lfs\r\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1623772440481
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\r\n",
    "    AutoConfig,\r\n",
    "    AutoModelForSeq2SeqLM,\r\n",
    "    AutoTokenizer\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1623774514973
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"../model/bart-large-samsum\"\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\r\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1623773816355
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#model.push_to_hub(\"bart-large-samsum\")\r\n",
    "tokenizer.push_to_hub(\"bart-large-samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1623774586530
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import json\r\n",
    "# read eval and test results \r\n",
    "with open(f\"{model_path}/eval_results.json\") as f:\r\n",
    "    eval_results_raw = json.load(f)\r\n",
    "    eval_results={}\r\n",
    "    eval_results[\"eval_rouge1\"] = eval_results_raw[\"eval_rouge1\"]\r\n",
    "    eval_results[\"eval_rouge2\"] = eval_results_raw[\"eval_rouge2\"]\r\n",
    "    eval_results[\"eval_rougeL\"] = eval_results_raw[\"eval_rougeL\"]\r\n",
    "    eval_results[\"eval_rougeLsum\"] = eval_results_raw[\"eval_rougeLsum\"]\r\n",
    "\r\n",
    "with open(f\"{model_path}/predict_results.json\") as f:\r\n",
    "    test_results_raw = json.load(f)\r\n",
    "    test_results={}\r\n",
    "    test_results[\"predict_rouge1\"] = test_results_raw[\"predict_rouge1\"]\r\n",
    "    test_results[\"predict_rouge2\"] = test_results_raw[\"predict_rouge2\"]\r\n",
    "    test_results[\"predict_rougeL\"] = test_results_raw[\"predict_rougeL\"]\r\n",
    "    test_results[\"predict_rougeLsum\"] = test_results_raw[\"predict_rougeLsum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1623775733020
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CARD_TEMPLATE = \"\"\"\r\n",
    "---\r\n",
    "language: en\r\n",
    "tags:\r\n",
    "- azureml\r\n",
    "- bart\r\n",
    "- summarization\r\n",
    "license: apache-2.0\r\n",
    "datasets:\r\n",
    "- samsum\r\n",
    "model-index:\r\n",
    "- name: {model_name}\r\n",
    "  results:\r\n",
    "  - task: \r\n",
    "      name: Abstractive Text Summarization\r\n",
    "      type: abstractive-text-summarization\r\n",
    "    dataset:\r\n",
    "      name: \"SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization\" \r\n",
    "      type: samsum\r\n",
    "widget:\r\n",
    "- text: | \r\n",
    "    Henry: Hey, is Nate coming over to watch the movie tonight?\r\n",
    "    Kevin: Yea, he said he'll start heading over here at around 7. Have you taken out the garbage yet?\r\n",
    "    Henry: Oh I forgot. I'll do that once I'm finished with my assignment for my math class.\r\n",
    "    Kevin: Yea, you should take it out as soon as possible. Also, Nate is bringing his cat.\r\n",
    "    Henry: Okay, see you then.\r\n",
    "---\r\n",
    "\r\n",
    "## `{model_name}`\r\n",
    "\r\n",
    "This model was trained using AzureML.\r\n",
    "\r\n",
    "\r\n",
    "## Usage\r\n",
    "```python\r\n",
    "from transformers import pipeline\r\n",
    "summarizer = pipeline(\"summarization\", model=\"henryu-lin/{model_name}\")\r\n",
    "\r\n",
    "conversation = '''Henry: Hey, is Nate coming over to watch the movie tonight?\r\n",
    "Kevin: Yea, he said he'll start heading over here at around 7. Have you taken out the garbage yet?\r\n",
    "Henry: Oh I forgot. I'll do that once I'm finished with my assignment for my math class.\r\n",
    "Kevin: Yea, you should take it out as soon as possible. Also, Nate is bringing his cat.\r\n",
    "Henry: Okay, see you then.\r\n",
    "'''\r\n",
    "nlp(conversation)\r\n",
    "```\r\n",
    "\r\n",
    "## Results\r\n",
    "\r\n",
    "| key | value |\r\n",
    "| --- | ----- |\r\n",
    "{eval_table}\r\n",
    "{test_table}\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "# Generate model card (todo: add more data from Trainer)\r\n",
    "model_card = MODEL_CARD_TEMPLATE.format(\r\n",
    "    model_name=f\"bart-large-samsum\",\r\n",
    "    #hyperparameters=json.dumps(hyperparameters, indent=4, sort_keys=True),\r\n",
    "    eval_table=\"\\n\".join(f\"| {k} | {v} |\" for k, v in eval_results.items()),\r\n",
    "    test_table=\"\\n\".join(f\"| {k} | {v} |\" for k, v in test_results.items()),\r\n",
    ")\r\n",
    "\r\n",
    "with open(f\"{model_path}/README.md\", \"w\") as f:\r\n",
    "    f.write(model_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1622906011749
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large\"\r\n",
    "xsum_config = AutoConfig.from_pretrained(\"./bart-large-xsum.json\", cache_dir=\"./cache\")\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"./cache\")\r\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=xsum_config, cache_dir=\"./cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1622906092036
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../model/bart-large/tokenizer_config.json',\n",
       " '../model/bart-large/special_tokens_map.json',\n",
       " '../model/bart-large/vocab.json',\n",
       " '../model/bart-large/merges.txt',\n",
       " '../model/bart-large/added_tokens.json',\n",
       " '../model/bart-large/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../model/bart-large\")\r\n",
    "tokenizer.save_pretrained(\"../model/bart-large\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
